{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPm55Z+luYLzRr/p/cmb+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeongJeong-code/P6_market_place/blob/main/text_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCq1wCSGpyTV",
        "outputId": "88a4b484-b204-4526-db3a-3fa7e0ad0ba9"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from enum import Enum\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os.path\n",
        "import missingno as mi\n",
        "import re\n",
        "import sklearn as sk\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.cluster import homogeneity_score\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.cluster import (AgglomerativeClustering,\n",
        "                             KMeans, DBSCAN, SpectralClustering)\n",
        "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
        "! {sys.executable} -m pip install ipynb\n",
        "\n",
        "import cv2\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipynb\n",
            "  Downloading ipynb-0.5.1-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: ipynb\n",
            "Successfully installed ipynb-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0KR3_WMqdbi",
        "outputId": "814cc374-9db8-4943-cabe-7c8018c64d70"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-NzHV6Jp0aQ"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/JeongJeong-code/P6_market_place/main/flipkart_com-ecommerce_sample_1050.csv'\n",
        "df_raw= pd.read_csv(url)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrENTbnIqOX0"
      },
      "source": [
        "desc_token = df_raw['description'].copy()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkVFRhiRqU1J"
      },
      "source": [
        "for i in range(len(desc_token)):\n",
        "  desc_token[i] = nltk.word_tokenize(df_raw.description[i])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APcW5uMUsZJG",
        "outputId": "aaa39307-f995-41f4-c980-287dca9459d2"
      },
      "source": [
        "desc_token[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Key',\n",
              " 'Features',\n",
              " 'of',\n",
              " 'Elegance',\n",
              " 'Polyester',\n",
              " 'Multicolor',\n",
              " 'Abstract',\n",
              " 'Eyelet',\n",
              " 'Door',\n",
              " 'Curtain',\n",
              " 'Floral',\n",
              " 'Curtain',\n",
              " ',',\n",
              " 'Elegance',\n",
              " 'Polyester',\n",
              " 'Multicolor',\n",
              " 'Abstract',\n",
              " 'Eyelet',\n",
              " 'Door',\n",
              " 'Curtain',\n",
              " '(',\n",
              " '213',\n",
              " 'cm',\n",
              " 'in',\n",
              " 'Height',\n",
              " ',',\n",
              " 'Pack',\n",
              " 'of',\n",
              " '2',\n",
              " ')',\n",
              " 'Price',\n",
              " ':',\n",
              " 'Rs',\n",
              " '.',\n",
              " '899',\n",
              " 'This',\n",
              " 'curtain',\n",
              " 'enhances',\n",
              " 'the',\n",
              " 'look',\n",
              " 'of',\n",
              " 'the',\n",
              " 'interiors.This',\n",
              " 'curtain',\n",
              " 'is',\n",
              " 'made',\n",
              " 'from',\n",
              " '100',\n",
              " '%',\n",
              " 'high',\n",
              " 'quality',\n",
              " 'polyester',\n",
              " 'fabric.It',\n",
              " 'features',\n",
              " 'an',\n",
              " 'eyelet',\n",
              " 'style',\n",
              " 'stitch',\n",
              " 'with',\n",
              " 'Metal',\n",
              " 'Ring.It',\n",
              " 'makes',\n",
              " 'the',\n",
              " 'room',\n",
              " 'environment',\n",
              " 'romantic',\n",
              " 'and',\n",
              " 'loving.This',\n",
              " 'curtain',\n",
              " 'is',\n",
              " 'ant-',\n",
              " 'wrinkle',\n",
              " 'and',\n",
              " 'anti',\n",
              " 'shrinkage',\n",
              " 'and',\n",
              " 'have',\n",
              " 'elegant',\n",
              " 'apparance.Give',\n",
              " 'your',\n",
              " 'home',\n",
              " 'a',\n",
              " 'bright',\n",
              " 'and',\n",
              " 'modernistic',\n",
              " 'appeal',\n",
              " 'with',\n",
              " 'these',\n",
              " 'designs',\n",
              " '.',\n",
              " 'The',\n",
              " 'surreal',\n",
              " 'attention',\n",
              " 'is',\n",
              " 'sure',\n",
              " 'to',\n",
              " 'steal',\n",
              " 'hearts',\n",
              " '.',\n",
              " 'These',\n",
              " 'contemporary',\n",
              " 'eyelet',\n",
              " 'and',\n",
              " 'valance',\n",
              " 'curtains',\n",
              " 'slide',\n",
              " 'smoothly',\n",
              " 'so',\n",
              " 'when',\n",
              " 'you',\n",
              " 'draw',\n",
              " 'them',\n",
              " 'apart',\n",
              " 'first',\n",
              " 'thing',\n",
              " 'in',\n",
              " 'the',\n",
              " 'morning',\n",
              " 'to',\n",
              " 'welcome',\n",
              " 'the',\n",
              " 'bright',\n",
              " 'sun',\n",
              " 'rays',\n",
              " 'you',\n",
              " 'want',\n",
              " 'to',\n",
              " 'wish',\n",
              " 'good',\n",
              " 'morning',\n",
              " 'to',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'world',\n",
              " 'and',\n",
              " 'when',\n",
              " 'you',\n",
              " 'draw',\n",
              " 'them',\n",
              " 'close',\n",
              " 'in',\n",
              " 'the',\n",
              " 'evening',\n",
              " ',',\n",
              " 'you',\n",
              " 'create',\n",
              " 'the',\n",
              " 'most',\n",
              " 'special',\n",
              " 'moments',\n",
              " 'of',\n",
              " 'joyous',\n",
              " 'beauty',\n",
              " 'given',\n",
              " 'by',\n",
              " 'the',\n",
              " 'soothing',\n",
              " 'prints',\n",
              " '.',\n",
              " 'Bring',\n",
              " 'home',\n",
              " 'the',\n",
              " 'elegant',\n",
              " 'curtain',\n",
              " 'that',\n",
              " 'softly',\n",
              " 'filters',\n",
              " 'light',\n",
              " 'in',\n",
              " 'your',\n",
              " 'room',\n",
              " 'so',\n",
              " 'that',\n",
              " 'you',\n",
              " 'get',\n",
              " 'the',\n",
              " 'right',\n",
              " 'amount',\n",
              " 'of',\n",
              " 'sunlight.',\n",
              " ',',\n",
              " 'Specifications',\n",
              " 'of',\n",
              " 'Elegance',\n",
              " 'Polyester',\n",
              " 'Multicolor',\n",
              " 'Abstract',\n",
              " 'Eyelet',\n",
              " 'Door',\n",
              " 'Curtain',\n",
              " '(',\n",
              " '213',\n",
              " 'cm',\n",
              " 'in',\n",
              " 'Height',\n",
              " ',',\n",
              " 'Pack',\n",
              " 'of',\n",
              " '2',\n",
              " ')',\n",
              " 'General',\n",
              " 'Brand',\n",
              " 'Elegance',\n",
              " 'Designed',\n",
              " 'For',\n",
              " 'Door',\n",
              " 'Type',\n",
              " 'Eyelet',\n",
              " 'Model',\n",
              " 'Name',\n",
              " 'Abstract',\n",
              " 'Polyester',\n",
              " 'Door',\n",
              " 'Curtain',\n",
              " 'Set',\n",
              " 'Of',\n",
              " '2',\n",
              " 'Model',\n",
              " 'ID',\n",
              " 'Duster25',\n",
              " 'Color',\n",
              " 'Multicolor',\n",
              " 'Dimensions',\n",
              " 'Length',\n",
              " '213',\n",
              " 'cm',\n",
              " 'In',\n",
              " 'the',\n",
              " 'Box',\n",
              " 'Number',\n",
              " 'of',\n",
              " 'Contents',\n",
              " 'in',\n",
              " 'Sales',\n",
              " 'Package',\n",
              " 'Pack',\n",
              " 'of',\n",
              " '2',\n",
              " 'Sales',\n",
              " 'Package',\n",
              " '2',\n",
              " 'Curtains',\n",
              " 'Body',\n",
              " '&',\n",
              " 'Design',\n",
              " 'Material',\n",
              " 'Polyester']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AugQA7XlryrM"
      },
      "source": [
        "import string\n",
        "from nltk.stem import PorterStemmer\n",
        "token_stop = desc_token.copy()\n",
        "stemmed_desc= desc_token.copy()\n",
        "wordnet_lemmatizer = nltk.WordNetLemmatizer()\n",
        "lemmatize_words = np.vectorize(wordnet_lemmatizer.lemmatize)\n",
        "porter= PorterStemmer()# vectorizing function to able to call on list of tokens\n",
        "stem_words = np.vectorize(porter.stem)\n",
        "for i in range(len(desc_token)):\n",
        "  nltk_stop_words = nltk.corpus.stopwords.words('english')\n",
        "  token_stop[i] = [t for t in desc_token[i] if t not in nltk_stop_words]\n",
        "  token_stop[i] = [t for t in token_stop[i] if t not in string.punctuation]\n",
        "  stemmed_text = stem_words(token_stop[i])\n",
        "  stemmed_desc[i] = stemmed_text\n",
        "  #display(f\"nltk text without stop words: {text_without_stop_words}\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_OEa6I5qZH5",
        "outputId": "da15dc1e-8701-4c62-bce1-5fda06bce48e"
      },
      "source": [
        "list(nltk.bigrams(stemmed_desc[0]))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('key', 'featur'),\n",
              " ('featur', 'eleg'),\n",
              " ('eleg', 'polyest'),\n",
              " ('polyest', 'multicolor'),\n",
              " ('multicolor', 'abstract'),\n",
              " ('abstract', 'eyelet'),\n",
              " ('eyelet', 'door'),\n",
              " ('door', 'curtain'),\n",
              " ('curtain', 'floral'),\n",
              " ('floral', 'curtain'),\n",
              " ('curtain', 'eleg'),\n",
              " ('eleg', 'polyest'),\n",
              " ('polyest', 'multicolor'),\n",
              " ('multicolor', 'abstract'),\n",
              " ('abstract', 'eyelet'),\n",
              " ('eyelet', 'door'),\n",
              " ('door', 'curtain'),\n",
              " ('curtain', '213'),\n",
              " ('213', 'cm'),\n",
              " ('cm', 'height'),\n",
              " ('height', 'pack'),\n",
              " ('pack', '2'),\n",
              " ('2', 'price'),\n",
              " ('price', 'Rs'),\n",
              " ('Rs', '899'),\n",
              " ('899', 'thi'),\n",
              " ('thi', 'curtain'),\n",
              " ('curtain', 'enhanc'),\n",
              " ('enhanc', 'look'),\n",
              " ('look', 'interiors.thi'),\n",
              " ('interiors.thi', 'curtain'),\n",
              " ('curtain', 'made'),\n",
              " ('made', '100'),\n",
              " ('100', 'high'),\n",
              " ('high', 'qualiti'),\n",
              " ('qualiti', 'polyest'),\n",
              " ('polyest', 'fabric.it'),\n",
              " ('fabric.it', 'featur'),\n",
              " ('featur', 'eyelet'),\n",
              " ('eyelet', 'style'),\n",
              " ('style', 'stitch'),\n",
              " ('stitch', 'metal'),\n",
              " ('metal', 'ring.it'),\n",
              " ('ring.it', 'make'),\n",
              " ('make', 'room'),\n",
              " ('room', 'environ'),\n",
              " ('environ', 'romant'),\n",
              " ('romant', 'loving.thi'),\n",
              " ('loving.thi', 'curtain'),\n",
              " ('curtain', 'ant-'),\n",
              " ('ant-', 'wrinkl'),\n",
              " ('wrinkl', 'anti'),\n",
              " ('anti', 'shrinkag'),\n",
              " ('shrinkag', 'eleg'),\n",
              " ('eleg', 'apparance.g'),\n",
              " ('apparance.g', 'home'),\n",
              " ('home', 'bright'),\n",
              " ('bright', 'modernist'),\n",
              " ('modernist', 'appeal'),\n",
              " ('appeal', 'design'),\n",
              " ('design', 'the'),\n",
              " ('the', 'surreal'),\n",
              " ('surreal', 'attent'),\n",
              " ('attent', 'sure'),\n",
              " ('sure', 'steal'),\n",
              " ('steal', 'heart'),\n",
              " ('heart', 'these'),\n",
              " ('these', 'contemporari'),\n",
              " ('contemporari', 'eyelet'),\n",
              " ('eyelet', 'valanc'),\n",
              " ('valanc', 'curtain'),\n",
              " ('curtain', 'slide'),\n",
              " ('slide', 'smoothli'),\n",
              " ('smoothli', 'draw'),\n",
              " ('draw', 'apart'),\n",
              " ('apart', 'first'),\n",
              " ('first', 'thing'),\n",
              " ('thing', 'morn'),\n",
              " ('morn', 'welcom'),\n",
              " ('welcom', 'bright'),\n",
              " ('bright', 'sun'),\n",
              " ('sun', 'ray'),\n",
              " ('ray', 'want'),\n",
              " ('want', 'wish'),\n",
              " ('wish', 'good'),\n",
              " ('good', 'morn'),\n",
              " ('morn', 'whole'),\n",
              " ('whole', 'world'),\n",
              " ('world', 'draw'),\n",
              " ('draw', 'close'),\n",
              " ('close', 'even'),\n",
              " ('even', 'creat'),\n",
              " ('creat', 'special'),\n",
              " ('special', 'moment'),\n",
              " ('moment', 'joyou'),\n",
              " ('joyou', 'beauti'),\n",
              " ('beauti', 'given'),\n",
              " ('given', 'sooth'),\n",
              " ('sooth', 'print'),\n",
              " ('print', 'bring'),\n",
              " ('bring', 'home'),\n",
              " ('home', 'eleg'),\n",
              " ('eleg', 'curtain'),\n",
              " ('curtain', 'softli'),\n",
              " ('softli', 'filter'),\n",
              " ('filter', 'light'),\n",
              " ('light', 'room'),\n",
              " ('room', 'get'),\n",
              " ('get', 'right'),\n",
              " ('right', 'amount'),\n",
              " ('amount', 'sunlight.'),\n",
              " ('sunlight.', 'specif'),\n",
              " ('specif', 'eleg'),\n",
              " ('eleg', 'polyest'),\n",
              " ('polyest', 'multicolor'),\n",
              " ('multicolor', 'abstract'),\n",
              " ('abstract', 'eyelet'),\n",
              " ('eyelet', 'door'),\n",
              " ('door', 'curtain'),\n",
              " ('curtain', '213'),\n",
              " ('213', 'cm'),\n",
              " ('cm', 'height'),\n",
              " ('height', 'pack'),\n",
              " ('pack', '2'),\n",
              " ('2', 'gener'),\n",
              " ('gener', 'brand'),\n",
              " ('brand', 'eleg'),\n",
              " ('eleg', 'design'),\n",
              " ('design', 'for'),\n",
              " ('for', 'door'),\n",
              " ('door', 'type'),\n",
              " ('type', 'eyelet'),\n",
              " ('eyelet', 'model'),\n",
              " ('model', 'name'),\n",
              " ('name', 'abstract'),\n",
              " ('abstract', 'polyest'),\n",
              " ('polyest', 'door'),\n",
              " ('door', 'curtain'),\n",
              " ('curtain', 'set'),\n",
              " ('set', 'Of'),\n",
              " ('Of', '2'),\n",
              " ('2', 'model'),\n",
              " ('model', 'ID'),\n",
              " ('ID', 'duster25'),\n",
              " ('duster25', 'color'),\n",
              " ('color', 'multicolor'),\n",
              " ('multicolor', 'dimens'),\n",
              " ('dimens', 'length'),\n",
              " ('length', '213'),\n",
              " ('213', 'cm'),\n",
              " ('cm', 'In'),\n",
              " ('In', 'box'),\n",
              " ('box', 'number'),\n",
              " ('number', 'content'),\n",
              " ('content', 'sale'),\n",
              " ('sale', 'packag'),\n",
              " ('packag', 'pack'),\n",
              " ('pack', '2'),\n",
              " ('2', 'sale'),\n",
              " ('sale', 'packag'),\n",
              " ('packag', '2'),\n",
              " ('2', 'curtain'),\n",
              " ('curtain', 'bodi'),\n",
              " ('bodi', 'design'),\n",
              " ('design', 'materi'),\n",
              " ('materi', 'polyest')]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1Zp6F3iv8X6",
        "outputId": "bcc38907-bda5-4279-bfec-c26f97cd37c6"
      },
      "source": [
        "stemmed_desc[0:5]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [key, featur, eleg, polyest, multicolor, abstr...\n",
              "1    [specif, sathiya, cotton, bath, towel, 3, bath...\n",
              "2    [key, featur, eurospa, cotton, terri, face, to...\n",
              "3    [key, featur, santosh, royal, fashion, cotton,...\n",
              "4    [key, featur, jaipur, print, cotton, floral, k...\n",
              "Name: description, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGNXEiYQrfBY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}