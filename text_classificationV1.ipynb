{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classificationV1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjzxRa5aQ6t7lWwK/sGelk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeongJeong-code/P6_market_place/blob/main/text_classificationV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8t9eQ39_KBR",
        "outputId": "07d207d1-dbe2-406a-9756-8736e247d50d"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from enum import Enum\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os.path\n",
        "import missingno as mi\n",
        "import re\n",
        "import sklearn as sk\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.cluster import homogeneity_score\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.cluster import (AgglomerativeClustering,\n",
        "                             KMeans, DBSCAN, SpectralClustering)\n",
        "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
        "! {sys.executable} -m pip install ipynb\n",
        "\n",
        "import cv2\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipynb in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw1hbEZe_PLa",
        "outputId": "247ba33b-4820-4d39-9ced-cb1b4ae29074"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVNhGXef_Tru"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/JeongJeong-code/P6_market_place/main/df1_test.csv'\n",
        "df1_test= pd.read_csv(url)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOpWDSk3_VAX"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk.stem\n",
        "import string"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGNB637k_aXv"
      },
      "source": [
        "nltk_stop_words = nltk.corpus.stopwords.words('english')\n",
        "nltk_stop_words.append(\"key\")\n",
        "nltk_stop_words.append(\"features\")\n",
        "desc_list = []\n",
        "desc_test = df1_test.description.copy()\n",
        "count_stop = CountVectorizer(lowercase= True, stop_words= nltk_stop_words,max_features=500,ngram_range=(1,1))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6uc6NFF_eFJ"
      },
      "source": [
        "for i in range(len(desc_test)):\n",
        "  desc_test[i]=''.join([t for t in desc_test[i] if not t.isdigit()])\n",
        "  desc_test[i]=''.join([t for t in desc_test[i] if t not in string.punctuation])\n",
        "  desc_test[i]=' '.join([t for t in desc_test[i].split() if len(t)>3])\n",
        "  desc_list.append(desc_test[i])\n",
        "  #X = vectorize_stop.fit_transform(desc_list)\n",
        "X= count_stop.fit_transform(desc_list)\n",
        "stop_words_list = list(nltk_stop_words) + list(count_stop.get_feature_names_out())#list(vectorize_stop.get_feature_names_out())"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRvztjhgAXGC"
      },
      "source": [
        "french_stemmer = nltk.stem.SnowballStemmer('english')\n",
        "class StemmedCountVectorizer(CountVectorizer):\n",
        "    def build_analyzer(self):\n",
        "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
        "        return lambda doc: ([french_stemmer.stem(w) for w in analyzer(doc)])\n",
        "\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrGZoyB3_kQQ"
      },
      "source": [
        "vect_st = StemmedCountVectorizer(lowercase= True, stop_words= stop_words_list,max_features=50,ngram_range=(1,1))\n",
        "vectorizer = TfidfVectorizer(lowercase= True, stop_words= stop_words_list,max_features=50,ngram_range=(1,1))\n",
        "desc_bag_list = []\n",
        "desc_bag = desc_test.copy()\n",
        "for j in range(len(desc_bag)):\n",
        "  desc_bag[j]=''.join([t for t in desc_bag[j] if not t.isdigit()])\n",
        "  desc_bag[j]=''.join([t for t in desc_bag[j] if t not in string.punctuation])\n",
        "  desc_bag[j]=' '.join([t for t in desc_bag[j].split() if len(t)>3])\n",
        "X_tf_idf = vectorizer.fit_transform(desc_bag)\n",
        "X_count = vect_st.fit_transform(desc_bag)\n",
        "    #display(j)\n",
        "desc_bag_list.append(vectorizer.get_feature_names_out())"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8irXzpAAnZH"
      },
      "source": [
        "#y = df1_test.categories.array\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(df1_test.categories)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y00gGOg_uoX",
        "outputId": "6b5a2ce6-c2ca-4dd5-b291-48055d2864b3"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "clf_tf_idf = BernoulliNB()\n",
        "clf_tf_idf.fit(X_tf_idf,y)\n",
        "\n",
        "clf_count = BernoulliNB()\n",
        "clf_count.fit(X_count,y)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so0Me7BEBC04",
        "outputId": "58dd61bf-26a0-4855-b6d2-bd26acbeff53"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores_tf_idf = cross_val_score(clf_tf_idf, X_tf_idf, y, cv=5, scoring='accuracy')\n",
        "print(scores_tf_idf)\n",
        "scores_count = cross_val_score(clf_count, X_count, y, cv=5, scoring='accuracy')\n",
        "print(scores_count)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.23655914 0.25806452 0.24193548 0.22702703 0.23243243]\n",
            "[0.29569892 0.23655914 0.24193548 0.25405405 0.29189189]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "n1HaqJlvBXp4",
        "outputId": "90952ed2-55f1-4f3b-ac1a-34bc9f084ee4"
      },
      "source": [
        "desc_test[0]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Features Elegance Polyester Multicolor Abstract Eyelet Door Curtain Floral CurtainElegance Polyester Multicolor Abstract Eyelet Door Curtain Height Pack Price This curtain enhances look interiorsThis curtain made from high quality polyester fabricIt features eyelet style stitch with Metal RingIt makes room environment romantic lovingThis curtain wrinkle anti shrinkage have elegant apparanceGive your home bright modernistic appeal with these designs surreal attention sure steal hearts These contemporary eyelet valance curtains slide smoothly when draw them apart first thing morning welcome bright rays want wish good morning whole world when draw them close evening create most special moments joyous beauty given soothing prints Bring home elegant curtain that softly filters light your room that right amount sunlightSpecifications Elegance Polyester Multicolor Abstract Eyelet Door Curtain Height Pack General Brand Elegance Designed Door Type Eyelet Model Name Abstract Polyester Door Curtain Model Duster Color Multicolor Dimensions Length Number Contents Sales Package Pack Sales Package Curtains Body Design Material Polyester'"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88Vi97bafhSu"
      },
      "source": [
        ""
      ],
      "execution_count": 76,
      "outputs": []
    }
  ]
}